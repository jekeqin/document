# 系统性能名词详解

## QPS / RT / TPS / 并发数
+ QPS
    + QPS是每秒钟处理完请求的次数。这里的请求不是指一个查询或者数据库查询，是包括一个业务逻辑的整个流程，也就是说每秒钟响应的请求次数。
    + QPS = 总请求数 / ( 进程总数 * 请求时间 )
    + 单个进程每秒请求服务器的成功次数
    + 峰值QPS
        + 原理：每天80%的访问集中在20%的时间里，这20%时间叫做峰值时间公式：( 总PV数 * 80% ) / ( 每天秒数 * 20% ) = 峰值时间每秒请求数(QPS)
+ RT  响应时间
    + 处理一次请求所需要的平均处理时间。对于RT，客户端和服务端是大不相同的，因为请求从客户端到服务端，需要经过广域网，所以客户端RT往往远大于服务端RT，同时客户端的RT往往决定着用户的真实体验，服务端RT往往是评估我们系统好坏的一个关键因素。
+ QPS和RT的关系
    + 单线程场景
        + 假设我们的服务端只有一个线程，那么所有的请求都是串行执行，我们可以很简单的算出系统的QPS，也就是：QPS = 1000ms/RT。假设一个RT过程中CPU计算的时间为49ms，CPU Wait Time 为200ms，那么QPS就为1000/(49+200) = 4.01。
    + 多线程场景
        + 我们接下来把服务端的线程数提升到2，那么整个系统的QPS则为：2 *(1000/(49+200))=8.02。可见QPS随着线程的增加而线性增长，那QPS上不去就加线程呗，听起来很有道理，公式也说得通，但是往往现实并非如此，后面会聊这个问题。
    + 最佳线程数
        + 从上面单线程场景来看，CPU Wait time为200ms,你可以理解为CPU这段时间什么都没做，是空闲的，显然我们没把CPU利用起来，这时候我们需要启多个线程去响应请求，把这部分利用起来，那么启动多少个线程呢？我们可以估算一下 空闲时间200ms，我们要把这部分时间转换为CPU Time,那么就是200+49/49 = 5.08个，不考虑上下文切换的话，约等于5个线程。同时还要考虑CPU的核心数和利用率问题，那么我们得到了最佳线程数计算的公式：RT/CPU Time * coreSize * cupRatio
    + 最大QPS
        + QPS = Thread num * 单线程QPS = （CPU Time + CPU Wait Time）/CPU Time * coreSize * CupRatio * (1000ms/(CPU Time + CPU Wait Time)) = 1000ms/(CPU Time) * coreSize * cpuRatio
        + 所以决定一个系统最大的QPS的因素是CPU Time、CoreSize和CPU利用率。看似增加CPU核数（或者说线程数）可以成倍的增加系统QPS，但实际上增加线程数的同时也增加了很大的系统负荷，更多的上下文切换，QPS和最大的QPS是有偏差的。
    + CPU Time & CPU Wait Time & CPU 利用率
        + CPU Time就是一次请求中，实际用到计算资源。CPU Time的消耗是全流程的，涉及到请求到应用服务器，再从应用服务器返回的全过程。实际上这取决于你的计算的复杂度。
        + CPU Wait Time是一次请求过程中对于IO的操作，CPU这段时间可以理解为空闲的，那么此时要尽量利用这些空闲时间，也就是增加线程数。
        + CPU 利用率是业务系统利用到CPU的比率，因为往往一个系统上会有一些其他的线程，这些线程会和CPU竞争计算资源，那么此时留给业务的计算资源比例就会下降，典型的像，GC线程的GC过程、锁的竞争过程都是消耗CPU的过程。甚至一些IO的瓶颈，也会导致CPU利用率下降(CPU都在Wait IO，利用率当然不高)。
    + 增加CPU核数对QPS的提升
        + 假设我们的串行部分不变的话，增大核数，CPU不能得到充分的利用，利用率也会降低。所以，对于阿姆达尔定律而言，串行化的比率才是决定着是否能成倍增长效率的关键。也就是说最佳线程数也好，最大QPS也好，增加内核数量不一定能是系统指标有成倍的增长。更关键的是能改变自己的架构，减小串行的比率，让CPU更充分的利用，达到资源的最大利用率。
    + 最佳线程数和最大QPS
        + 当线程数增加的时候，线程的上下文切换会增加，GC Time会增加。这也就导致CPU time 增加，QPS减小，RT也会随着增大。这显然不是我们希望的，我们希望的是在核数一定的情况下找到某个点，使系统的QPS最大，RT相对较小。所以我们需要不断的压测，调整线程池，找到这个QPS的峰值，并且使CPU的利用率达到100%,这样才是系统的最大QPS和最佳线程数。
+ TPS 吞吐量
    + 系统在单位时间内处理请求的数量。对于无并发的应用系统而言，吞吐量与响应时间成严格的反比关系，实际上此时吞吐量就是响应时间的倒数。前面已经说过，对于单用户的系统，响应时间（或者系统响应时间和应用延迟时间）可以很好地度量系统的性能，但对于并发系统，通常需要用吞吐量作为性能指标。
    + 对于一个多用户的系统，如果只有一个用户使用时系统的平均响应时间是t，当有你n个用户使用时，每个用户看到的响应时间通常并不是n×t，而往往比n×t小很多（当然，在某些特殊情况下也可能比n×t大，甚至大很多）。这是因为处理每个请求需要用到很多资源，由于每个请求的处理过程中有许多不走难以并发执行，这导致在具体的一个时间点，所占资源往往并不多。也就是说在处理单个请求时，在每个时间点都可能有许多资源被闲置，当处理多个请求时，如果资源配置合理，每个用户看到的平均响应时间并不随用户数的增加而线性增加。实际上，不同系统的平均响应时间随用户数增加而增长的速度也不大相同，这也是采用吞吐量来度量并发系统的性能的主要原因。一般而言，吞吐量是一个比较通用的指标，两个具有不同用户数和用户使用模式的系统，如果其最大吞吐量基本一致，则可以判断两个系统的处理能力基本一致。 
+ 并发数
    + 并发用户数
        + 某一物理时刻同时向系统提交请求的用户数，提交的请求可能是同一个场景或功能，也可以是不同场景或功能。在性能测试工具中，一般称为虚拟用户数(Virutal User)。
        + 在同一时刻与服务器进行了交互的在线用户数量。
        + 这些用户的最大特征是和服务器产生了交互，这种交互既可以是单向的传输数据，也可以是双向的传送数据。
        + 并发用户数量的统计的方法目前还没有准确的公式，因为不同系统会有不同的并发特点。
    + 在线用户数
        + 某段时间内访问系统的用户数，这些用户并不一定同时向系统提交请求
    + 系统用户数
        + 系统注册的总用户数据
    + 三者之间的关系
        + 系统用户数 >= 在线用户数 >= 并发用户数
+ TPS和并发用户数之间的关系
    + TPS就是每秒事务数，但是事务是基于虚拟用户数的，假如1个虚拟用户在1秒内完成1笔事务，那么TPS明显就是1；如果某笔业务响应时间是1ms,那么1个用户在1秒内能完成1000笔事务，TPS就是1000了；如果某笔业务响应时间是1s,那么1个用户在1秒内只能完成1笔事务，要想达到1000TPS，至少需要1000个用户；因此可以说1个用户可以产生1000TPS，1000个用户也可以产生1000TPS，无非是看响应时间快慢。
    + 也就是说，在评定服务器的性能时，应该结合TPS和并发用户数，以TPS为主，并发用户数为辅来衡量系统的性能。如果必须要用并发用户数来衡量的话，需要一个前提，那就是交易在多长时间内完成，因为在系统负载不高的情况下，将思考时间(思考时间的值等于交易响应时间)加到脚本中，并发用户数基本可以增加一倍，因此用并发用户数来衡量系统的性能没太大的意义。
    + 在性能测试时并不需要用上万的用户并发去进行测试，如果只需要保证系统处理业务时间足够快，几百个用户甚至几十个用户就可以达到目的。很多专家做过的性能测试项目基本都没有超过5000用户并发。因此对于大型系统、业务量非常高、硬件配置足够多的情况下，5000用户并发就足够了；对于中小型系统，1000用户并发就足够了。




## PV / UV / PR / DAU
+ PV 点击量
    + 访问量即Page View, 即页面浏览量或点击量，用户每次刷新即被计算一次单台服务器每天
+ UV 用户数量
    + 独立访客即Unique Visitor,访问您网站的一台电脑客户端为一个访客,在一段时间内。
+ PR 网站权重
    + PageRank，即网页的级别技术，或网站权重或受欢迎度。表示一个网页的重要程度。级别从1到10级，10级为满分。PR值越高说明该网页越受欢迎。
+ DAU 日活跃用户数量
    + Daily Active User日活跃用户数量。常用于反映网站、互联网应用或网络游戏的运营情况。DAU通常统计一日（统计日）之内，登录或使用了某个产品的用户数（去除重复登录的用户），这与流量统计工具里的访客（UV）概念相似。
+ MAU 月活数。
    + 统计一月（统计月）之内，登录或使用了某个产品的用户数（去除重复登录的用户），这与流量统计工具里的访客（UV）概念相似。



